{\rtf1\ansi\uc1\deff13\deflang1024
{\fonttbl{\f0\fnil\fcharset0 Zapf Chancery;}
{\f1\fnil\fcharset204 Zapf Chancery;}
{\f2\fnil\fcharset204 Times;}
{\f3\fnil\fcharset204 Helvetica;}
{\f4\fnil\fcharset204 Helvetica;}
{\f5\fnil\fcharset204 Courier;}
{\f6\fnil\fcharset2 Symbol;}
{\f7\fnil\fcharset0 MT Extra;}
{\f8\fnil\fcharset238 Zapf Chancery;}
{\f9\fnil\fcharset238 Times;}
{\f10\fnil\fcharset238 Helvetica;}
{\f11\fnil\fcharset238 Helvetica;}
{\f12\fnil\fcharset238 Courier;}
{\f13\fnil\fcharset0 Times;}
{\f14\fnil\fcharset0 Helvetica;}
{\f15\fnil\fcharset0 Helvetica;}
{\f16\fnil\fcharset0 Courier;}
}
{\colortbl;
\red0\green0\blue0;
\red0\green0\blue255;
\red0\green255\blue255;
\red0\green255\blue0;
\red255\green0\blue255;
\red255\green0\blue0;
\red255\green255\blue0;
\red255\green255\blue255;
\red0\green0\blue128;
\red0\green128\blue128;
\red0\green128\blue0;
\red128\green0\blue128;
\red128\green0\blue0;
\red128\green128\blue0;
\red128\green128\blue128;
\red192\green192\blue192;
}
{\stylesheet
{\s0\fs20\snext0 Normal;}
{\s2\ql\sb240\sa60\keepn\f13\b\fs40 \sbasedon0\snext0 heading 1;}
{\s2\ql\sb240\sa60\keepn\f13\b\fs40\li0 \sbasedon0\snext0 heading 1;}
{\s1\ql\sb240\sa60\keepn\f13\b\fs40\li0 \sbasedon0\snext0 heading 1;}
{\s6\ql\sb240\sa60\keepn\f13\b\fs24\li2048 \sbasedon0\snext0 heading 5;}
{\s3\ql\sb240\sa60\keepn\f13\b\fs32\li512 \sbasedon0\snext0 heading 2;}
{\s7\ql\sb240\sa60\keepn\f13\b\fs24\li2560 \sbasedon0\snext0 heading 6;}
{\s4\ql\sb240\sa60\keepn\f13\b\fs32\li1024 \sbasedon0\snext0 heading 3;}
{\s5\ql\sb240\sa60\keepn\f13\b\fs24\li1536 \sbasedon0\snext0 heading 4;}
{\s6\ql\sb240\sa60\keepn\f13\b\fs24 \sbasedon0\snext0 heading 5;}
{\s1\qc\sb240\sa60\keepn\f13\b\fs40 \sbasedon0\snext0 part;}
{\s3\ql\sb240\sa60\keepn\f13\b\fs32 \sbasedon0\snext0 heading 2;}
{\s7\ql\sb240\sa60\keepn\f13\b\fs24 \sbasedon0\snext0 heading 6;}
{\s4\ql\sb240\sa60\keepn\f13\b\fs32 \sbasedon0\snext0 heading 3;}
{\s5\ql\sb240\sa60\keepn\f13\b\fs24 \sbasedon0\snext0 heading 4;}
}
{\info
{\title Original file was ga_pso_evostar_2020_phpMu9Dje.tex}
{\doccomm Created using latex2rtf 1.9.19 (released Nov 20 2007) on Fri Nov  6 11:03:25 2020
}
}
{\footer\pard\plain\f13\fs20\qc\chpgn\par}
\paperw12280\paperh15900\margl2680\margr2700\margt2540\margb1760\pgnstart0\widowctrl\qj\ftnbj\f13\aftnnar
{\pard\qj\sl240\slmult1 \fi300 {F. Author et al.} {Princeton University, Princeton NJ 08544, USA \par
\pard\qj\sl240\slmult1 \fi300 Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany {lncs@springer.com}\par
{\f16 \field{\*\fldinst{ HYPERLINK "\pard\qj\sl240\slmult1 \fi0 http://www.springer.com/gp/computer-science/lncs" }{{}}}{\fldrslt{http://www.springer.com/gp/computer-science/lncs}}} \par
\pard\qj\sl240\slmult1 \fi300 ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\par
\pard\qj\sl240\slmult1 \fi0 {\{abc,lncs\}@uni-heidelberg.de}} 
\par\pard\qc {\fs30 Event-driven multi-population optimization: mixing Swarm and Evolutionary strategies}
\par\pard\qc {\fs24 First Author{1}{0000-1111-2222-3333} \par
\pard\qc\sl240\slmult1 \fi300 Second Author{2,3}{1111-2222-3333-4444} \par
\pard\qc\sl240\slmult1 \fi300 Third Author{3}{2222\endash 3333-4444-5555}}
\par\pard\qc {\fs24 }
\par\pard\qc {\fs24 }
\par\pard\qc {\fs24 }\par
{\pard\qj\sl240\slmult1 \fi0 \qc{\b Abstract}\par
\pard\qj\sl240\slmult1 \li1024\ri1024\fi0 Recently, in the field of nature-inspired optimization, researchers have proposed multi-population asynchronous algorithms that distribute the evolutionary process among heterogeneous search paradigms. These algorithms execute the search strategy by reading streams of populations from message queues, and replacing them with evolved versions of them. Moreover, current studies suggest that when we have a high number of populations interacting in parallel, the effect of the individual parameters of each population is compensated by those selected in other populations, improving the overall performance of the algorithm. In this work, we propose a simple reactive migration method for the asynchronous execution of multi-population, multi-strategy algorithms that improves over homogeneous configurations. We evaluate this method by comparing with homogeneous and an ensemble of multi-populations, using Genetic Algorithms (GAs) and Particle Swarm Optimization (PSO) in the noiseless BBOB testbed for the optimization of continuous functions. Results show, that this method offers better performance, even when compared with other asynchronous population based algorithms. {heterogeneous multi-population algorithms \par
\pard\qj\sl240\slmult1 \li1024\ri1024\fi300 genetic algorithms \par
\pard\qj\sl240\slmult1 \li1024\ri1024\fi300 cloud-native systems.} \par
}\pard\qj\sl240\slmult1 \sb360 \fi0 {\s3\ql\sb240\sa60\keepn\f13\b\fs32 1  Introduction\par
}\pard\qj\sl240\slmult1 \sb60 \fi0 Nature-inspired optimization algorithms have been used successfully in the last decades to tackle complex problems 
[{\field{\*\fldinst{\lang1024 REF BIB_yang2014nature \\* MERGEFORMAT }}{\fldrslt{yang2014nature}}}
]. These algorithms include evolutionary algorithms (EAs) 
[{\field{\*\fldinst{\lang1024 REF BIB_back1996evolutionary \\* MERGEFORMAT }}{\fldrslt{back1996evolutionary}}}
] and swarm intelligence (SI) 
[{\field{\*\fldinst{\lang1024 REF BIB_kennedy2006swarm \\* MERGEFORMAT }}{\fldrslt{kennedy2006swarm}}}
]. Genetic Algorithms (GAs) 
[{\field{\*\fldinst{\lang1024 REF BIB_holland1992adaptation \\* MERGEFORMAT }}{\fldrslt{holland1992adaptation}}}, {\field{\*\fldinst{\lang1024 REF BIB_eiben2003genetic \\* MERGEFORMAT }}{\fldrslt{eiben2003genetic}}}
], Differential Evolution (DE) 
[{\field{\*\fldinst{\lang1024 REF BIB_karabouga2004simple \\* MERGEFORMAT }}{\fldrslt{karabouga2004simple}}}
], and Genetic Programming (GP) 
[{\field{\*\fldinst{\lang1024 REF BIB_back1996evolutionary \\* MERGEFORMAT }}{\fldrslt{back1996evolutionary}}}
] are popular EAs, while examples of SI algorithms 
[{\field{\*\fldinst{\lang1024 REF BIB_kennedy2006swarm \\* MERGEFORMAT }}{\fldrslt{kennedy2006swarm}}}
] are particle swarm optimization (PSO) 
[{\field{\*\fldinst{\lang1024 REF BIB_clerc2010particle \\* MERGEFORMAT }}{\fldrslt{clerc2010particle}}}
], artificial bee colony (ABC) 
[{\field{\*\fldinst{\lang1024 REF BIB_karaboga2005idea \\* MERGEFORMAT }}{\fldrslt{karaboga2005idea}}}
], Grey Wolf Optimization (GWO) 
[{\field{\*\fldinst{\lang1024 REF BIB_mirjalili2014grey \\* MERGEFORMAT }}{\fldrslt{mirjalili2014grey}}}
], and ant colony algorithms (ACO) 
[{\field{\*\fldinst{\lang1024 REF BIB_dorigo1999ant \\* MERGEFORMAT }}{\fldrslt{dorigo1999ant}}}
]. A common characteristic of these kind of methods is the use of an initial set of random candidate solutions that are manipulated by the algorithm to generate a new set of candidates, and because of this, we commonly referred to them as population-based algorithms. There are other stochastic optimization methods, that even if they are not nature-inspired, they employ the concept of an evolving population. An example of this kind of methods is population-based incremental learning (PBIL) 
[{\field{\*\fldinst{\lang1024 REF BIB_baluja1994population \\* MERGEFORMAT }}{\fldrslt{baluja1994population}}}
], which is an optimization and an estimation of distribution algorithm. Since instead of piecewise constructing a population or changing it incrementally, all members of the population have to be evaluated to obtain a fitness or score that will be used to select them (or not), a drawback of this kind of algorithms is that they can be computationally expensive since it is difficult to overcome that {{{\i n}}} factor, where {{{\i n}}} is the population size, in the complexity of every iteration of the algorithm.\par
\pard\qj\sl240\slmult1 \fi300 That is the reason why researchers have been proposing some form of parallelization since early on 
[{\field{\*\fldinst{\lang1024 REF BIB_muhlenbein1988evolution \\* MERGEFORMAT }}{\fldrslt{muhlenbein1988evolution}}}
] with the goal of decreasing their execution time. One of the first methods of parallelization was the island model, which lead to an increased performance 
[{\field{\*\fldinst{\lang1024 REF BIB_gorges1990explicit \\* MERGEFORMAT }}{\fldrslt{gorges1990explicit}}}, {\field{\*\fldinst{\lang1024 REF BIB_grosso1985computer \\* MERGEFORMAT }}{\fldrslt{grosso1985computer}}}
]. The concept was to divide the population into smaller populations that communicated with each other. Other population-based algorithms have adopted the technique, and since then, researchers have found additional advantages besides a reduced execution speed, these include avoiding a premature convergence and maintaining the diversity of the global population 
[{\field{\*\fldinst{\lang1024 REF BIB_li2015multi \\* MERGEFORMAT }}{\fldrslt{li2015multi}}}
], we are going to call these methods multi-population algorithms 
[{\field{\*\fldinst{\lang1024 REF BIB_Ma2019 \\* MERGEFORMAT }}{\fldrslt{Ma2019}}}
]. The relative isolation in which populations carry out the algorithm, together with the synchronous or asynchronous communication, helps to increase the overall diversity since each population will search in a particular area, at least between communications. Multi-population algorithms use a form of communication to recombine or migrate candidate solutions between populations to avoid premature convergence, since smaller populations are known to perform better for a given problem than bigger populations 
[{\field{\*\fldinst{\lang1024 REF BIB_li2016multi \\* MERGEFORMAT }}{\fldrslt{li2016multi}}}, {\field{\*\fldinst{\lang1024 REF BIB_wu2016differential \\* MERGEFORMAT }}{\fldrslt{wu2016differential}}}
]. Even in some cases, a multi-population based algorithm scales better due to these interactions, and the parallelism of the operation 
[{\field{\*\fldinst{\lang1024 REF BIB_ALBA20027 \\* MERGEFORMAT }}{\fldrslt{ALBA20027}}}
]. \par
\pard\qj\sl240\slmult1 \fi300 Having many populations offers researchers many configuration options and additional challenges when designing efficient multi-population algorithms. Options include the number and size of populations, the interaction between them, the search area of each population, and the search strategy and its parametrization for each population. In this paper, we are interested in the latter, that is, having multiple populations running with distinct parameters and optimization algorithms. We can find in the literature, several heterogeneous multi-population algorithms that integrate variations of optimization algorithms, and these often perform better than single-population or homogeneous multi-population optimization algorithms
[{\field{\*\fldinst{\lang1024 REF BIB_wu2016differential \\* MERGEFORMAT }}{\fldrslt{wu2016differential}}}, {\field{\*\fldinst{\lang1024 REF BIB_nseef2016adaptive \\* MERGEFORMAT }}{\fldrslt{nseef2016adaptive}}}
]. Heterogeneous algorithms add to the problem of finding the correct parameter settings for each population; because some parameters affect the accuracy of the solution and the convergence speed of the individual algorithms as they tip the balance between exploration and exploitation of the search space. On the other hand, current studies show that by having a high number of populations communicating in parallel, the effect of the individual parameters of each population is compensated by those selected in other populations 
[{\field{\*\fldinst{\lang1024 REF BIB_li2016multi \\* MERGEFORMAT }}{\fldrslt{li2016multi}}}, {\field{\*\fldinst{\lang1024 REF BIB_tanabe2013evaluation \\* MERGEFORMAT }}{\fldrslt{tanabe2013evaluation}}}
]. Some level of heterogeneity can be implemented by just changing the configuration parameters of each population, but in this case, we are interested in heterogeneous search strategies.\par
\pard\qj\sl240\slmult1 \fi300 Therefore, in this paper, we implemented an asynchronous multi-population algorithm version, using a message queue for inter-process communication 
[{\field{\*\fldinst{\lang1024 REF BIB_guervos2018introducing \\* MERGEFORMAT }}{\fldrslt{guervos2018introducing}}}
], and a reactive migration procedure, in which we compare three heterogeneous configurations using a randomized parameter technique. We experimented with all populations using a GA or PSO search strategies, versus an ensemble multi-population with both GA and PSO algorithms, using as a benchmark, the separable functions of the BBOB noiseless testbed 
[{\field{\*\fldinst{\lang1024 REF BIB_hansen2009real \\* MERGEFORMAT }}{\fldrslt{hansen2009real}}}
]. We compare the options by measuring the average running time (aRT) as the number of functions (#FEs), as the objective is to prove that the advantage of heterogeneous configurations resides not only in the increased scalability but also in the search performance. \par
\pard\qj\sl240\slmult1 \fi300 The organization of the paper is as follows: First, Section {\field{\*\fldinst{\lang1024 REF BMsoa \\* MERGEFORMAT }}{\fldrslt{?}}} presents state of the art relevant to our work. In Section {\field{\*\fldinst{\lang1024 REF BMmethod \\* MERGEFORMAT }}{\fldrslt{?}}}, we present the proposed method. Section {\field{\*\fldinst{\lang1024 REF BMsetup \\* MERGEFORMAT }}{\fldrslt{?}}} describes the design of the empirical evaluation we designed to assess the effectiveness of the method, and in Section {\field{\*\fldinst{\lang1024 REF BMresults \\* MERGEFORMAT }}{\fldrslt{?}}}, we report and discuss the results. Finally, we offer the conclusions of this paper and suggestions on future work in Section {\field{\*\fldinst{\lang1024 REF BMconclusions \\* MERGEFORMAT }}{\fldrslt{?}}}.\par
\pard\qj\sl240\slmult1 \sb240 \fi0 {\s3\ql\sb240\sa60\keepn\f13\b\fs32 {\*\bkmkstart BMsoa}2{\*\bkmkend BMsoa}  State of the Art\par
}\pard\qj\sl240\slmult1 \sb60 \fi0 In general, population based algorithms have to keep a balance between exploration and exploitation via the clever use of selection and variation operators 
[{\field{\*\fldinst{\lang1024 REF BIB_vcrepinvsek2013exploration \\* MERGEFORMAT }}{\fldrslt{vcrepinvsek2013exploration}}}
]. In pursuit of that objective, it is important to keep diversity high 
[{\field{\*\fldinst{\lang1024 REF BIB_yuan2005importance \\* MERGEFORMAT }}{\fldrslt{yuan2005importance}}}
], but different algorithms have different mechanisms for increasing diversity (exploration) or decreasing it (exploitation). PSO has two constants that rule in which direction the {\i particle} is going to move: either randomly (exploration) or in the direction of the best particle (exploitation); evolutionary algorithms use mutation and, to a certain point, crossover for exploration and crossover and selection procedures for exploitation. Since these mechanisms are fundamentally different, using different and simultaneous algorithms might be considered a win-win situation by way of performing exploitation in several different directions, which will be able to get closer to the solution as well as generate new possibilities.\par
\pard\qj\sl240\slmult1 \fi300 This is why methods that mix several population-based algorithms have been repeatedly suggested in the literature: Pandi et al. 
[{\field{\*\fldinst{\lang1024 REF BIB_pandi2011dynamic \\* MERGEFORMAT }}{\fldrslt{pandi2011dynamic}}}
] suggest a combination of swarm intelligence and another algorithm denominated harmony search; Lien et al. 
[{\field{\*\fldinst{\lang1024 REF BIB_lien2012hybrid \\* MERGEFORMAT }}{\fldrslt{lien2012hybrid}}}
] combine particle swarm optimization with bee colony algorithms, while Zhao et al. 
[{\field{\*\fldinst{\lang1024 REF BIB_zhao2010hybrid \\* MERGEFORMAT }}{\fldrslt{zhao2010hybrid}}}
] combine the latter with evolutionary algorithms.\par
{\pard\qj\sl240\slmult1 \sb240 \fi0  \par
\pard\qc\sl240\slmult1 \fi0 {Table {\*\bkmkstart BMtab_equivalence}1{\*\bkmkend BMtab_equivalence}: Equivalence of terms between particle swarm optimization and evolutionary algorithms. }{\field{\*\fldinst TC "1 Equivalence of terms between particle swarm optimization and evolutionary algorithms. " \\f t}{\fldrslt }}\par
{\pard\qc\sl240\slmult1 \fi0 \par
\trowd\clbrdrl\brdrs\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\qc {PSO}\cell
\pard\intbl\qc {EA}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\qc {Position vector}\cell
\pard\intbl\qc {{\i genes} in a chromosome}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\qc {Move towards better}\cell
\pard\intbl\qc {Selection}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\qc {Random motion}\cell
\pard\intbl\qc {Mutation}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\qc {Move towards centroid}\cell
\pard\intbl\qc {Crossover}\cell
\row
} \par
}\pard\qj\sl240\slmult1 \sb240 \fi0 EAs and PSOs share another characteristic, besides the fact that they act on populations: they can use the same data structures to represent members of the population. Please check Table {\field{\*\fldinst{\lang1024 REF BMtab_equivalence \\* MERGEFORMAT }}{\fldrslt{?}}} for equivalence of terms between PSO and EAs; additionally to the data structures used, there is a certain equivalence in the operators, but they are different enough to perform search in different ways. The fact that they use the same data structures means that you can apply them in turns, or simply start calling a \ldblquote chromosome\rdblquote  a \ldblquote particle\rdblquote  or the other way round, without any conversion, and keep working with it with any of the algorithms.\par
\pard\qj\sl240\slmult1 \fi300 This is what the first papers to propose such a hybrid algorithm, by Robinson et al. 
[{\field{\*\fldinst{\lang1024 REF BIB_Robinson2002 \\* MERGEFORMAT }}{\fldrslt{Robinson2002}}}
], explicitly played on this fact and also on what we might call diversity of local minima by running an algorithm on a population until it became stagnated, and then switching to the other one. This was done apparently only once, but eventually the mixture of the two algorithms was able to obtain better results in the design of a kind of antenna called \ldblquote horn\rdblquote  than any of them separately, although they report that the best value was obtained by the algorithm that started as a PSO and terminated as an evolutionary one.\par
\pard\qj\sl240\slmult1 \fi300 Another kind of hybrid was proposed independently by Shi et al. 
[{\field{\*\fldinst{\lang1024 REF BIB_shi2003hybrid \\* MERGEFORMAT }}{\fldrslt{shi2003hybrid}}}
], citing the \ldblquote local optimum\rdblquote  problem, that is, the same as the previous one; it mixes both algorithms testing in different configurations: \ldblquote parallel\rdblquote  and \ldblquote serial\rdblquote  testing which configuration works better and is able to avoid that. Their results on benchmark functions are mixed; In general, however, a well-designed evolutionary or PSO algorithm will not fall in that local optimum; it is certainly true that, within a certain evaluation budget, neither might be able to find that global optimum. However, it is probably that they mean that, since exploitation of better-than-average solutions is done by the two algorithms in different directions, a hybrid algorithm might help the single-algorithm version to escape that.\par
\pard\qj\sl240\slmult1 \fi300 This better exploitation capability was used by Grimaldi et al. 
[{\field{\*\fldinst{\lang1024 REF BIB_grimaldi2005genetical \\* MERGEFORMAT }}{\fldrslt{grimaldi2005genetical}}}
], with the objective of solving electromagnetic problems. What they do is to split the population into two different populations which will be processed by an EA and a PSO algorithm; the new individuals generated are merged in a single population, which is then split all over again in the next iteration. This guarantees that none of the two algorithms is getting stuck, since the individuals will be randomly subjected to one or the other on every generation.\par
{\pard\qj\sl240\slmult1 \sb240 \fi300   \par
\pard\qc\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_kafkeo}1{\*\bkmkend BMfig_kafkeo}: General scheme of the architecture of this method. Numbers will be used to refer to its different elements in text.}{\field{\*\fldinst TC "1 General scheme of the architecture of this method. Numbers will be used to refer to its different elements in text." \\f f}{\fldrslt }}\par
}\pard\qj\sl240\slmult1 \sb240 \fi0 Later on, Esmin et al. 
[{\field{\*\fldinst{\lang1024 REF BIB_esmin2006hybrid \\* MERGEFORMAT }}{\fldrslt{esmin2006hybrid}}}
] leveraged to design their algorithms; this idea was later extended by Li et al. 
[{\field{\*\fldinst{\lang1024 REF BIB_li2008gene \\* MERGEFORMAT }}{\fldrslt{li2008gene}}}
]; in this work, chromosomes/particles represent Support Vector Machines, which are optimized to find the most representative features of gene expression data sets. PSO and EAs are applied serially: 10 iterations of each, after which the finalization criterion is examined; first PSO, then EA. Separate EA and PSO are tested against this hybrid algorithm, finding improvements of a few percent points in the accuracy over classification of the whole dataset. This marginal, but significant, improvement is essentially the kind of results that should be expected. While improvements in diversity always boost the results by allowing the algorithms to find better solutions, an order-of-magnitude difference is not usually achieved, since both algorithm, by themselves, have good mechanisms for global exploration.\par
\pard\qj\sl240\slmult1 \fi300 Several other hybrid algorithms have been proposed more recently: Gulia et al. 
[{\field{\*\fldinst{\lang1024 REF BIB_gulia2019hybrid \\* MERGEFORMAT }}{\fldrslt{gulia2019hybrid}}}
] mix ant colony optimization, which is a swarm intelligence algorithm, and EAs, to select software testing cases. ACO and EA are used serially, with GA acting to refine the test suite initially selected by the ant algorithm.\par
\pard\qj\sl240\slmult1 \fi300 The state of the art is, then, use swarm intelligence and evolutionary algorithms coupled to a population to which they are applied either one after the other, or splitting the population so that every one is applied to a part. In our case, however, population and algorithms are decoupled, and this decoupled architecture allows to mix algorithms in several different ways, which will be tested in this paper using the method explained next.\par
\pard\qj\sl240\slmult1 \sb240 \fi0 {\s3\ql\sb240\sa60\keepn\f13\b\fs32 {\*\bkmkstart BMmethod}3{\*\bkmkend BMmethod}  Proposed Method\par
}\pard\qj\sl240\slmult1 \sb60 \fi0 In this section, we present a model for the execution of multi-population based asynchronous algorithms. As a first step, we describe the general architecture, for handling a stream of continuously updated populations, and then our approach for decoupling the processing in stateless functions, to finally give details of the migration mechanism.\par
\pard\qj\sl240\slmult1 \sb120 \fi0 {\s4\ql\sb240\sa60\keepn\f13\b\fs32 {\*\bkmkstart BMarch}3.1{\*\bkmkend BMarch}  Architecture\par
}\pard\qj\sl240\slmult1 \sb60 \fi0 In this section we present our proposed model for the execution of multi-population based asynchronous algorithms. As we have mentioned before, when designing efficient multi-population algorithms, we need to consider additional issues 
[{\field{\*\fldinst{\lang1024 REF BIB_Ma2019 \\* MERGEFORMAT }}{\fldrslt{Ma2019}}}
], including the number and size of populations, how they interact or communicate between them, and the search strategy and parametrization of populations. We have considered these requirements and, in this paper, propose a cloud-native multi-population solution. In this model, populations are the primary data structure, and we package them as messages that are part of a continuous stream flowing from one computing node, performing an algorithm, to the next. To achieve this \ldblquote continuous stream,\rdblquote  everything must happen asynchronously without computing nodes needing to wait for others, and becoming available as soon as it is needed.\par
\pard\qj\sl240\slmult1 \fi300 We have implemented this streaming functionality by using a message queue system, whose general architecture is shown in Figure {\field{\*\fldinst{\lang1024 REF BMfig_kafkeo \\* MERGEFORMAT }}{\fldrslt{?}}}. We can explain the model by using an analogy of producers and consumers of messages. There are two queues, one labeled {\f16 input}, and the other one {\f16 output}. In a queue, {\i push} operations are represented by solid arrows connecting to the left side and pull or pop operations as solid arrows leaving from the right side. The {\f16 controller} process, is responsible for the migration of individuals from one population to the other, and keeping track of the iterations of the algorithm. There is at least one {\f16 stateless function} worker process responsible for running the isolated algorithms. The two processes {\f16 PSO} and {\f16 GA}, are shown.\par
\pard\qj\sl240\slmult1 \fi300 We can follow the path of messages as follows:\par
{\pard\qj\sl240\slmult1 \sb50 \li600\fi-300 1.\tab In this step, the specified number of populations are created according to the configuration. Populations at this moment are just static data messages, including each individual inside. Each population includes a metadata section where its algorithm and execution parameters are specified. For instance, for a GA, the mutation rate, type of crossover operator, and other values are indicated.\par
\pard\qj\sl240\slmult1 \sb50 \li600\fi-300 2.\tab The setup process pushes each population on to the {\f16 input} queue so that they can be consumed by stateless functions responsible for the execution of the search.\par
\pard\qj\sl240\slmult1 \sb50 \li600\fi-300 3.\tab One or more {\f16 stateless functions} are constantly pulling population messages from the {\f16 input} queue. These functions have the task of executing the optimization algorithm. They take the current state of the population and start to run the specified algorithm for a certain number of iterations.\par
\pard\qj\sl240\slmult1 \sb50 \li600\fi-300 4.\tab Once they finish the execution, the resulting populations are pushed to the {\f16 output} queue; when the computing node is done with a population, it draws another one from the queue.\par
\pard\qj\sl240\slmult1 \sb50 \li600\fi-300 5.\tab The {\f16 controller} pulls populations from the {\f16 output} queue, inspects the metadata describing the current state of the populations, and if the algorithm has found an optimal solution or the maximum number of iteration has been reached it stops the execution.\par
\pard\qj\sl240\slmult1 \sb50 \li600\fi-300 6.\tab Otherwise, it passes the stream of messages to a migration function, where populations are mixed. Migration generates new populations, and they are again pushed to the {\f16 input} queue to continue in a loop. The {\f16 controller} is also responsible for logging the metadata.\par
}\pard\qj\sl240\slmult1 \sb100 \fi0 This reactive architecture has the following advantages: {\par
\pard\qj\sl240\slmult1 \sb50 \li600\fi-300 \bullet\tab It decouples the population and the population-based algorithm. In this design, we can have one or many processing nodes, each running a different search strategy.\par
\pard\qj\sl240\slmult1 \sb50 \li600\fi-300 \bullet\tab Also, the reactive controller gives designers more control over the multi-population algorithm. In this process, designers can dynamically change the number of populations, population parameters, and migration details on-the-fly.\par
\pard\qj\sl240\slmult1 \sb50 \li600\fi-300 \bullet\tab Another advantage is that algorithm designers have many options for implementing this simple architecture. The same basic components can be implemented as a single multi-threaded program, or as a highly scalable serverless cloud application. \par
}\pard\qj\sl240\slmult1 \sb180 \fi0 {\s4\ql\sb240\sa60\keepn\f13\b\fs32 {\*\bkmkstart BMfunctions}3.2{\*\bkmkend BMfunctions}  Stateless functions\par
}\pard\qj\sl240\slmult1 \sb60 \fi0 This message queue pattern is an essential component of a highly scalable reactive architecture; one of the reasons for this scalability is the use of stateless functions that have no secondary effects, or the need to read data from an external entity. Stateless functions do not need to read, keep, or modify data outside of the scope of the method, it will have no side effects reading inputs and producing an output, mapping input to output as it were. If we implement population-based optimization algorithms using stateless functions, then to the system, there is no difference between having one or many copies of the same function pulling work from the queue all at the same time, because there are no unwanted side effects, including problems of resource locking resulting from this concurrency. This architecture has been implemented successfully for developing cloud-native multi-population algorithms, using serverless functions 
[{\field{\*\fldinst{\lang1024 REF BIB_garcia2018modern \\* MERGEFORMAT }}{\fldrslt{garcia2018modern}}}
], and concurrent programming 
[{\field{\*\fldinst{\lang1024 REF BIB_guervos2019improving \\* MERGEFORMAT }}{\fldrslt{guervos2019improving}}}
]. \par
\pard\qj\sl240\slmult1 \fi300 To have a stateless version of a population-based algorithm, we only need to skip the step of creating a random population. Instead, the function receives the population as a parameter along with the required parameters. After several iterations (specified in the parameters), the function returns the current state of the population, with additional data describing the local execution. This data is necessary to log the #FE and current fitness values.\par
\pard\qj\sl240\slmult1 \sb120 \fi0 {\s4\ql\sb240\sa60\keepn\f13\b\fs32 {\*\bkmkstart BMmigration}3.3{\*\bkmkend BMmigration}  Migration\par
}\pard\qj\sl240\slmult1 \sb60 \fi0 As the controller is pulling population messages from the output queue, it waits until the message queue contains three valid populations to trigger an event handled by the {\f16 population_mixer} function, which uses as an argument a list containing the three populations. This design has the advantage of not needing to keep a buffer in memory or external storage, and it follows the reactive paradigm. A possible disadvantage can be that it only mixes populations that have arrived sequentially to the message queue, but we could mitigate this with a larger buffer and in fact populations do not need to arrive to the buffer in the same order they were created or processed, so this shouldn\rquote t, in principle, contribute to any loss of diversity.\par
\pard\qj\sl240\slmult1 \fi300 When {\f16 population_mixer} unit receives a list of three populations, let us say [A, B, C], it calls the migration method shown in Algorithm {\field{\*\fldinst{\lang1024 REF BMalg_migration \\* MERGEFORMAT }}{\fldrslt{?}}} for [A, B], [B, C] and [A, C]. The migration algorithm sorts the individuals of each population and generates a new one by merging the best half from each. Finally, the {\f16 population_mixer} method pushes the three generated populations back to the {\f16 input} message queue.\par
{\pard\qj\sl240\slmult1 \fi0 \qc [Sorry. Ignored {\plain\f16\\begin\{algorithm\} ... \\end\{algorithm\}}]\par
}{\pard\qj\sl240\slmult1 \sb240 \fi300  {\par
\trowd\cellx6900
\pard\intbl\qc { \par
\pard\qj\sl240\slmult1 \fi300 }\cell
\row
\trowd\cellx6900
\pard\intbl\qc {\par
\pard\qj\sl240\slmult1 \fi300 }\cell
\row
}  \par
\pard\qc\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_avg}2{\*\bkmkend BMfig_avg}: Average running time (in #FEs as {{\field{\*\fldinst{ EQ {{\i l}{\i o}{\i g}\\s\\do5({\fs16 10})}}}{\fldrslt }}} value), divided by dimension for target function value {{\field{\*\fldinst{ EQ {10\\s\\up5({\fs16 {\f6\u-4051\'2D}8})}}}{\fldrslt }}} vs dimension. Black stars indicate a statistically better result compared to all other algorithms ({{{\i p}<0.01}}) and Bonferroni correction number of dimensions. Legend: {{NavyBlue}{{{\f6\'6F}}}}:GA-PSO-m, {{Magenta}{{{\f6\'A8}}}}:PSO-m, {{Orange}{{{\u8902*}}}}:GA-m, {{CornflowerBlue}{{{\u9663*}}}}:BIPOP-CMA-ES, {{red}{{}}}:DE, {{YellowGreen}{{{\u9653*}}}}:DE-PSO, {{cyan}{{}}}:EDA-PSO, {{GreenYellow}{{\field{\*\fldinst{ EQ {}}}{\fldrslt }}}}:GA, {{ForestGreen}{{}}}:PSO, {{Lavender}{{{\f6\'E0}}}}:LSstep, {{SkyBlue}{{{\f7\'3C}}}}:BrentSTEP }{\field{\*\fldinst TC "2 Average running time (in #FEs as {{\field{\*\fldinst{ EQ {{\i l}{\i o}{\i g}\\s\\do5({\fs16 10})}}}{\fldrslt }}} value), divided by dimension for target function value {{\field{\*\fldinst{ EQ {10\\s\\up5({\fs16 {\f6\u-4051\'2D}8})}}}{\fldrslt }}} vs dimension. Black stars indicate a statistically better result compared to all other algorithms ({{{\i p}<0.01}}) and Bonferroni correction number of dimensions. Legend: {{NavyBlue}{{{\f6\'6F}}}}:GA-PSO-m, {{Magenta}{{{\f6\'A8}}}}:PSO-m, {{Orange}{{{\u8902*}}}}:GA-m, {{CornflowerBlue}{{{\u9663*}}}}:BIPOP-CMA-ES, {{red}{{}}}:DE, {{YellowGreen}{{{\u9653*}}}}:DE-PSO, {{cyan}{{}}}:EDA-PSO, {{GreenYellow}{{\field{\*\fldinst{ EQ {}}}{\fldrslt }}}}:GA, {{ForestGreen}{{}}}:PSO, {{Lavender}{{{\f6\'E0}}}}:LSstep, {{SkyBlue}{{{\f7\'3C}}}}:BrentSTEP " \\f f}{\fldrslt }}\par
}\pard\qj\sl240\slmult1 \sb480 \fi0 {\s3\ql\sb240\sa60\keepn\f13\b\fs32 {\*\bkmkstart BMsetup}4{\*\bkmkend BMsetup}  Experimental setup\par
}\pard\qj\sl240\slmult1 \sb60 \fi0 In this section, we present the experimental setup needed to verify if having a multi-population algorithm, with heterogeneous populations and the support for mixing search strategies, increases the performance of the search by needing fewer function evaluations than a homogeneous setting.\par
\pard\qj\sl240\slmult1 \fi300 benchmark separable functions ({{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 1}){\i t}{\i o}{\i f}\\s\\do5({\fs16 5})}}}{\fldrslt }}}) from the Continuous Noiseless BBOB testbed, which is part of the Comparing Continuous Optimizers (COCO) framework 
[{\field{\*\fldinst{\lang1024 REF BIB_hansen2016coco \\* MERGEFORMAT }}{\fldrslt{hansen2016coco}}}
]. \par
\pard\qj\sl240\slmult1 \fi300 Although there are not many real-world problems that are entirely separable, we wanted to focus on separable functions as a primary benchmark for testing the performance of a hybrid multi-population algorithm. And there is interest in solving such problems using more general methods 
[{\field{\*\fldinst{\lang1024 REF BIB_doerr2013evolutionary \\* MERGEFORMAT }}{\fldrslt{doerr2013evolutionary}}}, {\field{\*\fldinst{\lang1024 REF BIB_swarzberg1994step \\* MERGEFORMAT }}{\fldrslt{swarzberg1994step}}}
]. These functions are real-parameter, single-objective, and are usually employed as benchmarks. We have tested with fifteen instances of each function, each one having a different optimal value. The standard benchmark of the testbed 40 dimensions. With the maximum number of function evaluations (#FEs) increasing with the dimension (D), using the expression {{\field{\*\fldinst{ EQ {10\\s\\up5({\fs16 5}){\f6\u-3881\'D7}{\i D}}}}{\fldrslt }}} (i.e. for {{{\i D}=2}}, #FEs is {{200,000}}).\par
\pard\qj\sl240\slmult1 \fi300 The COCO framework offers several tools to compare the performance of algorithms, generating data sets, tables, and reports for an experiment, we have compared using the average required time (aRT). There is a repository{\up16\chftn}
{\*\footnote \pard\plain\s246\f13\fs20 {\up16\chftn}{\f16 \field{\*\fldinst{ HYPERLINK "https://coco.gforge.inria.fr/doku.php?id=algorithms-bbob" }{{}}}{\fldrslt{https://coco.gforge.inria.fr/doku.php?id=algorithms-bbob}}}}
 of more than 200 results for the noiseless BBOB testbed, collected from BBOB workshops and special sessions between the years 2009 and 2019. To test the heterogeneous multi-population capabilities, we have compared the aRT between a homogeneous and an ensemble of multi-populations, using Genetic Algorithms (GAs) and Particle Swarm Optimization (PSO).\par
\pard\qj\sl240\slmult1 \fi300 We have used the DEAP framework for the GA stateless function 
[{\field{\*\fldinst{\lang1024 REF BIB_fortin2012deap \\* MERGEFORMAT }}{\fldrslt{fortin2012deap}}}
] and the EvoloPy library 
[{\field{\*\fldinst{\lang1024 REF BIB_faris2016evolopy \\* MERGEFORMAT }}{\fldrslt{faris2016evolopy}}}
] for the PSO algorithm function. We show the parameters for each algorithm in Tables {\field{\*\fldinst{\lang1024 REF BMtab_GAparams \\* MERGEFORMAT }}{\fldrslt{?}}} and Table {\field{\*\fldinst{\lang1024 REF BMtab_PSOparams \\* MERGEFORMAT }}{\fldrslt{?}}} for the GA and PSO, respectively. We have obtained these parameters by following a method used by Garc\'C3\'ADa et al. in 
[{\field{\*\fldinst{\lang1024 REF BIB_garcia2017benchmarking \\* MERGEFORMAT }}{\fldrslt{garcia2017benchmarking}}}
]. First, we tested the parameters for the Rastrigin separable function with five dimensions. After about fifteen experiments, the most challenging targets were achieved for this particular function. We tested again with functions one to three, and after obtaining favorable results, we set the PSO and GA algorithm parameters. We have set the mutation and crossover probabilities of the GA randomly to have heterogeneous populations; the entry in the Table shows the range of these parameters. We have not changed these settings during the experiments, and we have only provided the population size and number of generations as parameters.\par
{\pard\qj\sl240\slmult1 \sb240 \fi0 \fs18 \par
\pard\qc\sl240\slmult1 \fi0 {Table {\*\bkmkstart BMtab_GAparams}2{\*\bkmkend BMtab_GAparams}:  DEAP GA EvoWorker Parameters }{\field{\*\fldinst TC "2  DEAP GA EvoWorker Parameters " \\f t}{\fldrslt }}\par
\fs18 {\pard\qc\sl240\slmult1 \fi0 \par
\trowd\clbrdrl\brdrs\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\ql {Selection}\cell
\pard\intbl\qc {Tournament size=12}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\ql {Mutation}\cell
\pard\intbl\qc {Gaussian {{{\f6\'6D}=0.0}}, {{{\f6\'73}=0.5}}, indbp=0.05}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\ql {Mutation Probability}\cell
\pard\intbl\qc {[0.1,0.3]}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\ql {Crossover}\cell
\pard\intbl\qc {Two Point}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\ql {Crossover Probability}\cell
\pard\intbl\qc {[0.2,0.6]}\cell
\row
} \par
}{\pard\qj\sl240\slmult1 \sb480 \fi0 \fs18 \par
\pard\qc\sl240\slmult1 \fi0 {Table {\*\bkmkstart BMtab_PSOparams}3{\*\bkmkend BMtab_PSOparams}:  EvoloPy PSO Parameters }{\field{\*\fldinst TC "3  EvoloPy PSO Parameters " \\f t}{\fldrslt }}\par
\fs18 {\pard\qc\sl240\slmult1 \fi0 \par
\trowd\clbrdrl\brdrs\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\ql {{{\field{\*\fldinst{ EQ {{\i V}\\s\\do4({\fs15 {\i m}{\i a}{\i x}})}}}{\fldrslt }}}}\cell
\pard\intbl\qc {6}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\ql {{{\field{\*\fldinst{ EQ {{\i W}\\s\\do4({\fs15 {\i m}{\i a}{\i x}})}}}{\fldrslt }}}}\cell
\pard\intbl\qc {{{0.9}}}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\ql {{{\field{\*\fldinst{ EQ {{\i W}\\s\\do4({\fs15 {\i m}{\i i}{\i n}})}}}{\fldrslt }}}}\cell
\pard\intbl\qc {{{0.2}}}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\ql {{{\field{\*\fldinst{ EQ {{\i C}\\s\\do4({\fs15 1})}}}{\fldrslt }}}}\cell
\pard\intbl\qc {2}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3450\clbrdrb\brdrs\clbrdrr\brdrs\cellx6900
\pard\intbl\ql {{{\field{\*\fldinst{ EQ {{\i C}\\s\\do4({\fs15 2})}}}{\fldrslt }}}}\cell
\pard\intbl\qc {2}\cell
\row
} \par
}\pard\qj\sl240\slmult1 \sb240 \fi0 To run the experiments, we have deployed the Docker application with 8 worker containers hosting the stateless version of the GA and PSO algorithms described earlier, and a total of 10 populations. Table {\field{\*\fldinst{\lang1024 REF BMtab_params_10 \\* MERGEFORMAT }}{\fldrslt{?}}} shows the parameters we have used. The {\i GA-PSO Ratio} parameter specifies the proportion of populations that will be using the GA algorithm, with {{0}} indicating all populations will run a PSO algorithm, and with {{0.5}} the same proportion of PSO and GA populations, and GA only it is specified with {{1}}. We have specified that the experiment will use only the first five functions. We have used 15 instances, because this is the standard for the BBOB benchmark 
[{\field{\*\fldinst{\lang1024 REF BIB_hansen2016coco \\* MERGEFORMAT }}{\fldrslt{hansen2016coco}}}
]. The list of dimensions that we have tested is in the {\i Dimensions} parameter. Then, we have defined for each dimension: the number of populations, and for each population, the number of generations and population size. Finally, we have defined how many complete loops the algorithm will perform. The product of these parameters gives us a maximum #FEs. For example, for {{{\i D}=2}}, the maximum number evaluations is {{200,000}}, this is the same as the product of the parameters, that is {{40*50*10*10}}. \par
{\pard\qj\sl240\slmult1 \sb240 \fi0  \fs18 \par
\pard\qc\sl240\slmult1 \fi0 {Table {\*\bkmkstart BMtab_params_10}4{\*\bkmkend BMtab_params_10}: Parameters used in the experiments, for ten populations and eight workers. }{\field{\*\fldinst TC "4 Parameters used in the experiments, for ten populations and eight workers. " \\f t}{\fldrslt }}\par
\fs18 {\pard\qc\sl240\slmult1 \sb142 \fi0 \par
\trowd\clbrdrl\brdrs\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx985\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx1970\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx2955\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx3940\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx4925\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx5910\clbrdrt\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx6895
\pard\intbl\ql {Dimension}\cell
\pard\intbl\qc {2}\cell
\pard\intbl\qc {3}\cell
\pard\intbl\qc {5}\cell
\pard\intbl\qc {10}\cell
\pard\intbl\qc {20}\cell
\pard\intbl\qc {40}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx985\clbrdrb\brdrs\clbrdrr\brdrs\cellx1970\clbrdrb\brdrs\clbrdrr\brdrs\cellx2955\clbrdrb\brdrs\clbrdrr\brdrs\cellx3940\clbrdrb\brdrs\clbrdrr\brdrs\cellx4925\clbrdrb\brdrs\clbrdrr\brdrs\cellx5910\clbrdrb\brdrs\clbrdrr\brdrs\cellx6895
\pard\intbl\ql {Generations}\cell
\pard\intbl\qc {40}\cell
\pard\intbl\qc {25}\cell
\pard\intbl\qc {28}\cell
\pard\intbl\qc {50}\cell
\pard\intbl\qc {66}\cell
\pard\intbl\qc {80}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx985\clbrdrb\brdrs\clbrdrr\brdrs\cellx1970\clbrdrb\brdrs\clbrdrr\brdrs\cellx2955\clbrdrb\brdrs\clbrdrr\brdrs\cellx3940\clbrdrb\brdrs\clbrdrr\brdrs\cellx4925\clbrdrb\brdrs\clbrdrr\brdrs\cellx5910\clbrdrb\brdrs\clbrdrr\brdrs\cellx6895
\pard\intbl\ql {Population Size}\cell
\pard\intbl\qc {50}\cell
\pard\intbl\qc {60}\cell
\pard\intbl\qc {60}\cell
\pard\intbl\qc {70}\cell
\pard\intbl\qc {100}\cell
\pard\intbl\qc {125}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx985\clbrdrb\brdrs\clbrdrr\brdrs\cellx1970\clbrdrb\brdrs\clbrdrr\brdrs\cellx2955\clbrdrb\brdrs\clbrdrr\brdrs\cellx3940\clbrdrb\brdrs\clbrdrr\brdrs\cellx4925\clbrdrb\brdrs\clbrdrr\brdrs\cellx5910\clbrdrb\brdrs\clbrdrr\brdrs\cellx6895
\pard\intbl\ql {Populations}\cell
\pard\intbl\qc {10}\cell
\pard\intbl\qc {10}\cell
\pard\intbl\qc {10}\cell
\pard\intbl\qc {10}\cell
\pard\intbl\qc {10}\cell
\pard\intbl\qc {10}\cell
\row
\trowd\clbrdrl\brdrs\clbrdrb\brdrs\clbrdrr\brdrs\cellx985\clbrdrb\brdrs\clbrdrr\brdrs\cellx1970\clbrdrb\brdrs\clbrdrr\brdrs\cellx2955\clbrdrb\brdrs\clbrdrr\brdrs\cellx3940\clbrdrb\brdrs\clbrdrr\brdrs\cellx4925\clbrdrb\brdrs\clbrdrr\brdrs\cellx5910\clbrdrb\brdrs\clbrdrr\brdrs\cellx6895
\pard\intbl\ql {Iterations}\cell
\pard\intbl\qc {10}\cell
\pard\intbl\qc {20}\cell
\pard\intbl\qc {30}\cell
\pard\intbl\qc {30}\cell
\pard\intbl\qc {30}\cell
\pard\intbl\qc {40}\cell
\row
} \par
}\pard\qj\sl240\slmult1 \sb240 \fi0 We have deployed the container-based application in a Desktop PC with AMD Ryzen 9 3900x 12-core processor with 24 threads and 16 GB RAM. We used Docker version 19.03.3, build a872fc2f86, and {\i0\scaps0\b0\f16 docker-compose} version 1.21.0, in Ubuntu Linux 18.04, and Python 3.7.5 code. Container images and Docker compose file are available at (https://hub.docker.com/x/x), and (https://github.com/x/). The experiments were performed with COCO 
[{\field{\*\fldinst{\lang1024 REF BIB_hansen2016coco \\* MERGEFORMAT }}{\fldrslt{hansen2016coco}}}
] version bbob.v15.03 in python, the plots were produced with version 2.3.2.\par
\pard\qj\sl240\slmult1 \sb240 \fi0 {\s3\ql\sb240\sa60\keepn\f13\b\fs32 {\*\bkmkstart BMresults}5{\*\bkmkend BMresults}  Results\par
}\pard\qj\sl240\slmult1 \sb60 \fi0 The results obtained by the experiments show (see Figure {\field{\*\fldinst{\lang1024 REF BMfig_bbob \\* MERGEFORMAT }}{\fldrslt{?}}}) how the runtime scales with dimension to reach certain target values {{{\f6\'44}{\i f}}}; The color of the lines indicates the average runtime, for each target reached at least one time. A red circle without a number on top indicates the algorithm has reached the {{\field{\*\fldinst{ EQ {10\\s\\up5({\fs16 {\f6\u-4051\'2D}8})}}}{\fldrslt }}} target on all instances for that dimension. If there is a number on the top, it indicates how many times the algorithm has reached the target. Fixed values of targets {{\field{\*\fldinst{ EQ {{\f6\u-4028\'44}{\i f}=10\\s\\up5({\fs16 {\i k}})}}}{\fldrslt }}} with {{{\i k}}} colors are given in the legend of {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 1})}}}{\fldrslt }}}, {{{\i k}}} values are {{[{\f6\'2D}8,{\f6\'2D}5,{\f6\'2D}3,{\f6\'2D}2,{\f6\'2D}1,0,1]}}. Results from each configuration are presented in each column, GA, PSO, and GA&PSO populations.\par
\pard\qj\sl240\slmult1 \fi300 We can see that the GA algorithm (on the left column) has a hard time reaching even the {{\field{\*\fldinst{ EQ {10\\s\\up5({\fs16 {\f6\u-4051\'2D}5})}}}{\fldrslt }}} target in functions ({{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 1}){\f6\u-4051\'2D}{\i f}\\s\\do5({\fs16 4})}}}{\fldrslt }}}) for all dimensions, and has the worst performance in 20 and 40 dimensions. Finally, it performs better on {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 5})}}}{\fldrslt }}} reaching the {{\field{\*\fldinst{ EQ {10\\s\\up5({\fs16 {\f6\u-4051\'2D}8})}}}{\fldrslt }}} on all dimensions but with a higher runtime on lower dimensions.\par
\pard\qj\sl240\slmult1 \fi300 On the other hand, the multi-population PSO (taking the column on the middle) has better performance; its results take a smaller range, reaching all targets for functions {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 1})}}}{\fldrslt }}} and {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 2})}}}{\fldrslt }}} but with a slightly higher runtime than the multi-strategy configuration. It is not able to reach the {{\field{\*\fldinst{ EQ {10\\s\\up5({\fs16 {\f6\u-4051\'2D}8})}}}{\fldrslt }}} target on the higher dimensions of {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 3})}}}{\fldrslt }}} and {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 4})}}}{\fldrslt }}}. Moreover, the PSO multi-population has the best runtime for the lower dimensions of {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 5})}}}{\fldrslt }}}.\par
\pard\qj\sl240\slmult1 \fi300 Finally, the proposed PSO&GA mixed algorithm has reached the {{\field{\*\fldinst{ EQ {10\\s\\up5({\fs16 {\f6\u-4051\'2D}8})}}}{\fldrslt }}} target value on all functions ({{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 1}){\f6\u-4051\'2D}{\i f}\\s\\do5({\fs16 5})}}}{\fldrslt }}}) and scales well to higher dimensions, even on {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 3})}}}{\fldrslt }}} and {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 4})}}}{\fldrslt }}} (charts on the lower rows), which are usually considered difficult functions. \par
\pard\qj\sl240\slmult1 \fi300 These results are also competitive when compared against other GA and PSO implementations of past BBOB workshops. Figure {\field{\*\fldinst{\lang1024 REF BMfig_avg \\* MERGEFORMAT }}{\fldrslt{?}}} shows how the runtime scales with dimension to reach the most difficult target for {{\field{\*\fldinst{ EQ {{\f6\u-4028\'44}{\i f}=10\\s\\up5({\fs16 {\f6\u-4051\'2D}8})}}}{\fldrslt }}} for each function. The representative algorithms are: The simple binary GA algorithm of Nicolau 
[{\field{\*\fldinst{\lang1024 REF BIB_nicolau2009application \\* MERGEFORMAT }}{\fldrslt{nicolau2009application}}}
], the PSO algorithm by El-Abd and Kamel 
[{\field{\*\fldinst{\lang1024 REF BIB_el2009black \\* MERGEFORMAT }}{\fldrslt{el2009black}}}
], an EDA and PSO hybrid 
[{\field{\*\fldinst{\lang1024 REF BIB_el2009blackHybrid \\* MERGEFORMAT }}{\fldrslt{el2009blackHybrid}}}
], Differential Evolution (DE) with adaptive encoding 
[{\field{\*\fldinst{\lang1024 REF BIB_povsik2012benchmarking \\* MERGEFORMAT }}{\fldrslt{povsik2012benchmarking}}}
] by {Po{\u353s}{\'ec}k and Klem{\u353s}, the hybrid DE-PSO by Garc{\'ec}a-Nieto et al. 
[{\field{\*\fldinst{\lang1024 REF BIB_garcia2009noiseless \\* MERGEFORMAT }}{\fldrslt{garcia2009noiseless}}}
], and the BIPOP-CMA-ES algorithm 
[{\field{\*\fldinst{\lang1024 REF BIB_hansen2009benchmarking \\* MERGEFORMAT }}{\fldrslt{hansen2009benchmarking}}}
] by Hansen, this last algorithm has the best overall ({{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 1}){\f6\u-4051\'2D}{\i f}\\s\\do5({\fs16 2})4}}}{\fldrslt }}}) performance on the BOBB-2009 benchmark, as it could solve 23, 22 and 20 functions out of 24 in dimensions 10, 20 and 40, respectively. \par
\pard\qj\sl240\slmult1 \fi300 We also compare with two methods that are not population-based, but univariate solvers generalized for the optimization of separable functions, the line-search algorithm LSStep by Po{\u353s}{\'ec}k 
[{\field{\*\fldinst{\lang1024 REF BIB_povsik2009bbob \\* MERGEFORMAT }}{\fldrslt{povsik2009bbob}}}
], and the Hybrid Brent-STEP by Po{\u353s}{\'ec}k and Baudi{\u353s} 
[{\field{\*\fldinst{\lang1024 REF BIB_povsik2015dimension \\* MERGEFORMAT }}{\fldrslt{povsik2015dimension}}}
]. The performance for the Brent-STEP algorithm is the best for this group of functions, finding all targets with le FEs.\par
\pard\qj\sl240\slmult1 \fi300 We can see that the number of evaluations of {\i0\scaps0\b0\f14 GA-PSO-m} tends to be higher in most cases, but on the other hand, it could solve all functions while others could not. As expected, the BIPOP-CMA-ES algorithm has the best running time on functions {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 1})}}}{\fldrslt }}}, {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 2})}}}{\fldrslt }}} and {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 5})}}}{\fldrslt }}} and reaches three targets at search dimensions 20 and 40. It is worth to notice the performance of the DE algorithm, having the best running time on lower dimensions of {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 3})}}}{\fldrslt }}} and {{\field{\*\fldinst{ EQ {{\i f}\\s\\do5({\fs16 4})}}}{\fldrslt }}}.\par
\pard\qj\sl240\slmult1 \fi300 Figure {\field{\*\fldinst{\lang1024 REF BMfig_bbob2 \\* MERGEFORMAT }}{\fldrslt{?}}}, highlights the performance of our proposal in search space dimensions 10, 20, and 40. The figure shows the fraction of functions-target pairs by the number of FEs. In this case, an algorithm that requires less FEs to reach all targets will have more area under the curve. For higher dimensions, the GA-PSO multi-population gives competitive results by reaching all targets within budget. The Brent-STEP algorithm did not provide results for 40D.\par
{\pard\qj\sl240\slmult1 \sb240 \fi300  {\par
\trowd\cellx2300\cellx4600\cellx6900
\pard\intbl\qc {GA}\cell
\pard\intbl\qc {PSO}\cell
\pard\intbl\qc {GA & PSO}\cell
\row
\trowd\cellx2300\cellx4600\cellx6900
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\row
\trowd\cellx2300\cellx4600\cellx6900
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\row
\trowd\cellx2300\cellx4600\cellx6900
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\row
\trowd\cellx2300\cellx4600\cellx6900
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\row
\trowd\cellx2300\cellx4600\cellx6900
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\row
}  \par
\pard\qc\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_bbob}3{\*\bkmkend BMfig_bbob}:  Scaling of running time with problem dimension to reach certain target values {{{\f6\'44}{\i f}}}. Lines: average runtime (aRT); Cross ({{+}}): median runtime of successful runs to reach the most difficult target that was reached at least once (but not always); Cross ({\cf6 {{{\f6\'B4}}}}): maximum number of f-evaluations in any trial. Notched boxes: interquartile range with median of simulated runs; all values are divided by dimension and plotted as {{\field{\*\fldinst{ EQ {{\i l}{\i o}{\i g}\\s\\do5({\fs16 10})}}}{\fldrslt }}} values versus dimension. }{\field{\*\fldinst TC "3  Scaling of running time with problem dimension to reach certain target values {{{\f6\'44}{\i f}}}. Lines: average runtime (aRT); Cross ({{+}}): median runtime of successful runs to reach the most difficult target that was reached at least once (but not always); Cross ({\cf6 {{{\f6\'B4}}}}): maximum number of f-evaluations in any trial. Notched boxes: interquartile range with median of simulated runs; all values are divided by dimension and plotted as {{\field{\*\fldinst{ EQ {{\i l}{\i o}{\i g}\\s\\do5({\fs16 10})}}}{\fldrslt }}} values versus dimension. " \\f f}{\fldrslt }}\par
}{\pard\qj\sl240\slmult1 \sb480 \fi0  {\par
\trowd\cellx2300\cellx4600\cellx6900
\pard\intbl\qc {10D}\cell
\pard\intbl\qc {20D}\cell
\pard\intbl\qc {40D}\cell
\row
\trowd\cellx2300\cellx4600\cellx6900
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\pard\intbl\qc {}\cell
\row
}  \par
\pard\qc\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_bbob2}4{\*\bkmkend BMfig_bbob2}:  Bootstrapped empirical cumulative distribution of the number of objective function evaluations divided by dimension (FEvals/DIM) for separable functions. }{\field{\*\fldinst TC "4  Bootstrapped empirical cumulative distribution of the number of objective function evaluations divided by dimension (FEvals/DIM) for separable functions. " \\f f}{\fldrslt }}\par
}\pard\qj\sl240\slmult1 \sb480 \fi0 {\s3\ql\sb240\sa60\keepn\f13\b\fs32 {\*\bkmkstart BMconclusions}6{\*\bkmkend BMconclusions}  Conclusions and future lines of work\par
}\pard\qj\sl240\slmult1 \sb60 \fi0 In this paper we have presented a new multi-population, hybrid, stateless bioinspired algorithm that uses different processing units to evolve sets of populations, which behave as a stream of continuously updated messages. Population and evolution (or any other kind of change) are totally decoupled, and its processing is stateless, which makes possible to create a mixture of processing algorithms that work asynchronously and in a way that\rquote s totally independent of each other.\par
\pard\qj\sl240\slmult1 \fi300 We have tested this combination of algorithms on the BBOB benchmark functions, obtaining results that are better that those obtained by any of them separated. This confirms results obtained by previous authors in hybrid algorithms, except that, in this case, the architecture is different and there are improvements all across the tested functions; besides, results are better than results that have been published for other algorithms, including a hybrid one, making the hybrid PSO/GA a firm contender in the function optimization arena. It is interesting to note that this is done despite mixing both algorithms in a totally random way, so that it\rquote s really impossible to know whether an individual population will be processed by a GA or PSO, or how many cycles of each has undergone. The migration process, however, guarantees a mixing of results and is probably the key to the ultimate success of the algorithm proposed here. As future lines of work, we will try to add different population-based, data-compatible algorithms to the mix, to see what kind of results they obtain and what could possible be the best possible mix. A way of automatically scaling to get the number of nodes needed would also be a very interesting feature.\par
\pard\qj\sl240\slmult1 \fi300 An extensive study on the real effects of the mix of algorithms should also be performed, with a theoretical basis if possible, using the size of the basins of attractions, for instance, or how different algorithms move along the fitness landscape.\par
\pard\qj\sl240\slmult1 \sb240 \fi0 {\s3\ql\sb240\sa60\keepn\f13\b\fs32 Acknowledgments\par
}\pard\qj\sl240\slmult1 \sb60 \fi0 The authors would also like to thank the anonymous referees for their valuable comments and helpful suggestions. The work is supported by the so and so.\par
}}
